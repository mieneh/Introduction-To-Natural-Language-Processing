{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxHQQ13BmexU"
   },
   "source": [
    "#Khai báo thư viện và đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fVTC62Mkyzsv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import TFBertForTokenClassification, BertConfig\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "OU9HFL_UdzRs",
    "outputId": "e06ffe8a-16d2-416e-c861-83b35717ab7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5ce649b6-4468-4652-8229-d6f5c3e485e2\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5ce649b6-4468-4652-8229-d6f5c3e485e2\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpus\n",
      "License(s): DbCL-1.0\n",
      "Downloading entity-annotated-corpus.zip to /content\n",
      " 95% 25.0M/26.4M [00:02<00:00, 22.2MB/s]\n",
      "100% 26.4M/26.4M [00:02<00:00, 12.6MB/s]\n",
      "Archive:  entity-annotated-corpus.zip\n",
      "  inflating: ner.csv                 \n",
      "  inflating: ner_dataset.csv         \n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện Kaggle\n",
    "!pip install kaggle\n",
    "# Tải lên tệp kaggle.json của bạn chứa thông tin xác thực API\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "# Di chuyển tệp đã tải lên vào thư mục cần thiết\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "# Thiết lập quyền truy cập\n",
    "#!chmod 600 ~/.kaggle/kaggle.json\n",
    "# Bây giờ bạn có thể tải tập dữ liệu bằng lệnh API Kaggle\n",
    "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus\n",
    "# Giải nén tập dữ liệu\n",
    "!unzip entity-annotated-corpus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t30yf04omqED",
    "outputId": "cf5b638c-7907-48bd-d831-93cc69c97709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sentence #           Word  POS    Tag\n",
      "0   Sentence: 1      Thousands  NNS      O\n",
      "1   Sentence: 1             of   IN      O\n",
      "2   Sentence: 1  demonstrators  NNS      O\n",
      "3   Sentence: 1           have  VBP      O\n",
      "4   Sentence: 1        marched  VBN      O\n",
      "5   Sentence: 1        through   IN      O\n",
      "6   Sentence: 1         London  NNP  B-geo\n",
      "7   Sentence: 1             to   TO      O\n",
      "8   Sentence: 1        protest   VB      O\n",
      "9   Sentence: 1            the   DT      O\n",
      "10  Sentence: 1            war   NN      O\n",
      "11  Sentence: 1             in   IN      O\n",
      "12  Sentence: 1           Iraq  NNP  B-geo\n",
      "13  Sentence: 1            and   CC      O\n",
      "14  Sentence: 1         demand   VB      O\n",
      "15  Sentence: 1            the   DT      O\n",
      "16  Sentence: 1     withdrawal   NN      O\n",
      "17  Sentence: 1             of   IN      O\n",
      "18  Sentence: 1        British   JJ  B-gpe\n",
      "19  Sentence: 1         troops  NNS      O\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu\n",
    "data = pd.read_csv('ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method='ffill')\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL8UZMlU61fi"
   },
   "source": [
    "# Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LB3ajIn94Oc2"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                          s[\"POS\"].values.tolist(),\n",
    "                                                          s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences\n",
    "\n",
    "# Chuẩn bị dữ liệu cho RNN và BiLSTM\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T_gFSpuU4aOh"
   },
   "outputs": [],
   "source": [
    "# Chuyển đổi dữ liệu\n",
    "max_len = 75\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "\n",
    "# Chia tập dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6i9FasH7BM6"
   },
   "source": [
    "# Xây dựng các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xifR_5_Fscnj",
    "outputId": "f75dcd22-6f10-43b5-d7b6-d36dae73c2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 75, 50)            1758900   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 75, 100)           15100     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 75, 17)            1717      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1775717 (6.77 MB)\n",
      "Trainable params: 1775717 (6.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình RNN\n",
    "model_rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_words, output_dim=50, input_length=max_len),\n",
    "    tf.keras.layers.SimpleRNN(units=100, return_sequences=True, recurrent_dropout=0.1),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_tags, activation='softmax'))\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzBgaDhopaZG",
    "outputId": "a7eb6759-429d-47c0-ea27-c302368907cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 75, 50)            1758900   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 75, 200)           120800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 75, 17)            3417      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1883117 (7.18 MB)\n",
      "Trainable params: 1883117 (7.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình BiLSTM\n",
    "model_bilstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_words, output_dim=50, input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=100, return_sequences=True, \\\n",
    "                                                       recurrent_dropout=0.1)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_tags, activation='softmax'))\n",
    "])\n",
    "\n",
    "model_bilstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jrEg0At7Es1"
   },
   "source": [
    "# Huấn luyện các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJVGJjaNhbr1",
    "outputId": "43f0a43a-27a6-43e2-c29f-0ace3589c11c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1214/1214 [==============================] - 164s 129ms/step - loss: 0.1295 - accuracy: 0.9734 - val_loss: 0.0437 - val_accuracy: 0.9875\n",
      "Epoch 2/3\n",
      "1214/1214 [==============================] - 120s 99ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 3/3\n",
      "1214/1214 [==============================] - 117s 96ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0360 - val_accuracy: 0.9889\n",
      "Epoch 1/3\n",
      "1214/1214 [==============================] - 580s 472ms/step - loss: 0.1297 - accuracy: 0.9719 - val_loss: 0.0434 - val_accuracy: 0.9877\n",
      "Epoch 2/3\n",
      "1214/1214 [==============================] - 563s 464ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.0326 - val_accuracy: 0.9902\n",
      "Epoch 3/3\n",
      "1214/1214 [==============================] - 558s 459ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0307 - val_accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "history_rnn = model_rnn.fit(X_train, np.array(y_train), batch_size=32, \\\n",
    "                            epochs=3, validation_split=0.1)\n",
    "\n",
    "history_bilstm = model_bilstm.fit(X_train, np.array(y_train), batch_size=32, \\\n",
    "                                  epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7O7zmPeg7Jhe"
   },
   "source": [
    "# Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "F695um3XzzIa"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    loss, accuracy = model.evaluate(X, y)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    y_true = np.argmax(y_test, axis=-1).flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    print(\"Báo cáo phân loại:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=tags, zero_division='warn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOUb3A8a7Pxw",
    "outputId": "e7229e8c-7a0c-46cb-e892-bdfa306a6a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá mô hình RNN:\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9887\n",
      "Loss: 0.0366535484790802, Accuracy: 0.9887072443962097\n",
      "150/150 [==============================] - 1s 7ms/step\n",
      "Báo cáo phân loại:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-gpe       0.93      0.62      0.74        21\n",
      "       I-org       0.78      0.73      0.76      1725\n",
      "       B-art       0.50      0.03      0.05        35\n",
      "       B-nat       0.75      0.21      0.33        28\n",
      "       B-eve       1.00      0.17      0.29        24\n",
      "       I-per       0.87      0.84      0.85      1742\n",
      "       B-geo       0.83      0.87      0.85      3828\n",
      "       B-org       0.69      0.62      0.65      2072\n",
      "       I-art       0.00      0.00      0.00        33\n",
      "       B-tim       0.91      0.82      0.86      2020\n",
      "       I-nat       0.00      0.00      0.00        10\n",
      "           O       1.00      1.00      1.00    343475\n",
      "       I-geo       0.78      0.80      0.79       732\n",
      "       B-gpe       0.94      0.94      0.94      1556\n",
      "       I-tim       0.76      0.71      0.74       671\n",
      "       I-eve       0.00      0.00      0.00        23\n",
      "       B-per       0.82      0.81      0.82      1705\n",
      "\n",
      "    accuracy                           0.99    359700\n",
      "   macro avg       0.68      0.54      0.57    359700\n",
      "weighted avg       0.99      0.99      0.99    359700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình RNN\n",
    "print(\"Đánh giá mô hình RNN:\")\n",
    "evaluate_model(model_rnn, X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RTACidE7VTW",
    "outputId": "ba3419c4-b1e2-426c-b7d0-28e624168fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá mô hình BiLSTM:\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.0312 - accuracy: 0.9905\n",
      "Loss: 0.031210968270897865, Accuracy: 0.9905115365982056\n",
      "150/150 [==============================] - 16s 107ms/step\n",
      "Báo cáo phân loại:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-gpe       1.00      0.43      0.60        21\n",
      "       I-org       0.80      0.77      0.78      1725\n",
      "       B-art       0.00      0.00      0.00        35\n",
      "       B-nat       0.00      0.00      0.00        28\n",
      "       B-eve       1.00      0.17      0.29        24\n",
      "       I-per       0.87      0.82      0.84      1742\n",
      "       B-geo       0.88      0.88      0.88      3828\n",
      "       B-org       0.77      0.74      0.75      2072\n",
      "       I-art       0.00      0.00      0.00        33\n",
      "       B-tim       0.90      0.89      0.90      2020\n",
      "       I-nat       0.00      0.00      0.00        10\n",
      "           O       1.00      1.00      1.00    343475\n",
      "       I-geo       0.78      0.81      0.80       732\n",
      "       B-gpe       0.96      0.93      0.95      1556\n",
      "       I-tim       0.76      0.77      0.76       671\n",
      "       I-eve       0.00      0.00      0.00        23\n",
      "       B-per       0.84      0.81      0.83      1705\n",
      "\n",
      "    accuracy                           0.99    359700\n",
      "   macro avg       0.62      0.53      0.55    359700\n",
      "weighted avg       0.99      0.99      0.99    359700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình BiLSTM\n",
    "print(\"Đánh giá mô hình BiLSTM:\")\n",
    "evaluate_model(model_bilstm, X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyRjn1rk7amg"
   },
   "source": [
    "# Dự đoán nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_lx5iLOsjoq6"
   },
   "outputs": [],
   "source": [
    "idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "\n",
    "def predict_and_print(model, sentence):\n",
    "    sentence_transformed = pad_sequences([[word2idx.get(w, word2idx[\"ENDPAD\"]) for w in sentence.split()]], maxlen=max_len, padding=\"post\", value=n_words-1)\n",
    "    pred = model.predict(sentence_transformed)\n",
    "    pred_tags = np.argmax(pred, axis=-1)\n",
    "    words_tags = [(word, idx2tag[pred_tags[0][i]]) if pred_tags[0][i] < len(tag2idx) else (word, 'O') for i, word in enumerate(sentence.split())]\n",
    "    # In kết quả dự đoán\n",
    "    print(\"Kết quả dự đoán:\")\n",
    "    for word, tag in words_tags:\n",
    "        print(f\"{word}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ue6cH0Vl7o9H",
    "outputId": "dbbe3727-b296-4dc6-8333-76a534a94777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dự đoán và in kết quả sử dụng mô hình BiLSTM:\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Kết quả dự đoán:\n",
      "John: B-per\n",
      "Lee: I-per\n",
      "is: O\n",
      "the: O\n",
      "chief: O\n",
      "of: O\n",
      "CBSE,: O\n",
      "Americans: B-gpe\n",
      "suffered: O\n",
      "from: O\n",
      "H5N1: O\n",
      "virus: O\n",
      "in: O\n",
      "2002: B-tim\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán và in kết quả sử dụng mô hình RNN\n",
    "print(\"\\nDự đoán và in kết quả sử dụng mô hình BiLSTM:\")\n",
    "predict_and_print(model_rnn, \"John Lee is the chief of CBSE, Americans suffered from H5N1 virus in 2002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdLEWWJoHqLc",
    "outputId": "46c262c6-cfec-4454-8b51-5dd356e0dc52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dự đoán và in kết quả sử dụng mô hình BiLSTM:\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Kết quả dự đoán:\n",
      "John: B-per\n",
      "Lee: I-per\n",
      "is: O\n",
      "the: O\n",
      "chief: O\n",
      "of: O\n",
      "CBSE,: O\n",
      "Americans: B-gpe\n",
      "suffered: O\n",
      "from: O\n",
      "H5N1: O\n",
      "virus: O\n",
      "in: O\n",
      "2002: B-tim\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán và in kết quả sử dụng mô hình BiLSTM\n",
    "print(\"\\nDự đoán và in kết quả sử dụng mô hình BiLSTM:\")\n",
    "predict_and_print(model_bilstm, \"John Lee is the chief of CBSE, Americans suffered from H5N1 virus in 2002\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
